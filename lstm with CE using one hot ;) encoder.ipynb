{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/StephanieBrito/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import mido\n",
    "import os\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MidiFile('Data/devorame-lalo.mid')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program_change channel=9 program=2 time=0\n",
      "program_change channel=5 program=0 time=0\n",
      "program_change channel=3 program=32 time=0\n",
      "program_change channel=9 program=0 time=0\n",
      "program_change channel=4 program=62 time=0\n",
      "program_change channel=0 program=57 time=0\n",
      "program_change channel=9 program=2 time=0\n",
      "program_change channel=1 program=53 time=0\n"
     ]
    }
   ],
   "source": [
    "notes = []\n",
    "\n",
    "def isPercussion(channel):\n",
    "    return channel in range(8, 17) or channel in range(35, 82)\n",
    "\n",
    "for msg in mid:\n",
    "    if msg.type == 'program_change':\n",
    "        print(msg)\n",
    "    if not msg.is_meta and msg.channel == 0 and msg.type == 'note_on':\n",
    "        data = msg.bytes()\n",
    "        notes.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample data for training and prediction\n",
    "X = []\n",
    "y = []\n",
    "# number of notes in a batch\n",
    "n_prev = 8\n",
    "n_to_predict = 2\n",
    "for i in range(len(notes)-n_prev):\n",
    "    X.append(notes[i:i+n_prev])\n",
    "    y.append(notes[i+n_prev])\n",
    "# save a seed to do prediction later\n",
    "X_test = X[-300:]\n",
    "X = np.asarray(X[:-300])\n",
    "y = y[:-300]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-03c5c981f7af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mencoded_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# convert integers to dummy variables (i.e. one hot encoded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdummy_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2332\u001b[0m     \"\"\"\n\u001b[1;32m   2333\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2334\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "print(len(dummy_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=n_prev, activation='relu'))\n",
    "    model.add(Dense(len(dummy_y[0]), activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4568/4568 [==============================] - 1s 133us/step - loss: 7.7628 - acc: 0.0508\n",
      "Epoch 2/50\n",
      "4568/4568 [==============================] - 0s 52us/step - loss: 3.6433 - acc: 0.1003\n",
      "Epoch 3/50\n",
      "4568/4568 [==============================] - 0s 67us/step - loss: 3.5577 - acc: 0.1022\n",
      "Epoch 4/50\n",
      "4568/4568 [==============================] - 0s 53us/step - loss: 3.4979 - acc: 0.1020\n",
      "Epoch 5/50\n",
      "4568/4568 [==============================] - 0s 46us/step - loss: 3.4499 - acc: 0.1020\n",
      "Epoch 6/50\n",
      "4568/4568 [==============================] - 0s 50us/step - loss: 3.4099 - acc: 0.1020\n",
      "Epoch 7/50\n",
      "4568/4568 [==============================] - 0s 49us/step - loss: 3.3766 - acc: 0.1020\n",
      "Epoch 8/50\n",
      "4568/4568 [==============================] - 0s 48us/step - loss: 3.3491 - acc: 0.1022\n",
      "Epoch 9/50\n",
      "4568/4568 [==============================] - 0s 49us/step - loss: 3.3263 - acc: 0.1022\n",
      "Epoch 10/50\n",
      "4568/4568 [==============================] - 0s 47us/step - loss: 3.3070 - acc: 0.1022\n",
      "Epoch 11/50\n",
      "4568/4568 [==============================] - 0s 49us/step - loss: 3.2907 - acc: 0.1022\n",
      "Epoch 12/50\n",
      "4568/4568 [==============================] - 0s 49us/step - loss: 3.2766 - acc: 0.1022\n",
      "Epoch 13/50\n",
      "4568/4568 [==============================] - 0s 51us/step - loss: 3.2649 - acc: 0.1020\n",
      "Epoch 14/50\n",
      "4568/4568 [==============================] - 0s 47us/step - loss: 3.2550 - acc: 0.1035\n",
      "Epoch 15/50\n",
      "4568/4568 [==============================] - 0s 69us/step - loss: 3.2473 - acc: 0.1046\n",
      "Epoch 16/50\n",
      "4568/4568 [==============================] - 0s 66us/step - loss: 3.2405 - acc: 0.1046\n",
      "Epoch 17/50\n",
      "4568/4568 [==============================] - 0s 53us/step - loss: 3.2341 - acc: 0.1055\n",
      "Epoch 18/50\n",
      "4568/4568 [==============================] - 0s 67us/step - loss: 3.2285 - acc: 0.1057\n",
      "Epoch 19/50\n",
      "4568/4568 [==============================] - 0s 54us/step - loss: 3.2240 - acc: 0.1060\n",
      "Epoch 20/50\n",
      "4568/4568 [==============================] - 0s 63us/step - loss: 3.2202 - acc: 0.1053\n",
      "Epoch 21/50\n",
      "4568/4568 [==============================] - 0s 53us/step - loss: 3.2158 - acc: 0.1060\n",
      "Epoch 22/50\n",
      "4568/4568 [==============================] - 0s 52us/step - loss: 3.2119 - acc: 0.1064\n",
      "Epoch 23/50\n",
      "4568/4568 [==============================] - 0s 53us/step - loss: 3.2083 - acc: 0.1051\n",
      "Epoch 24/50\n",
      "4568/4568 [==============================] - 0s 63us/step - loss: 3.2044 - acc: 0.1053\n",
      "Epoch 25/50\n",
      "4568/4568 [==============================] - 0s 52us/step - loss: 3.1996 - acc: 0.1060\n",
      "Epoch 26/50\n",
      "4568/4568 [==============================] - 0s 50us/step - loss: 3.1957 - acc: 0.1053\n",
      "Epoch 27/50\n",
      "4568/4568 [==============================] - 0s 59us/step - loss: 3.1962 - acc: 0.1051\n",
      "Epoch 28/50\n",
      "4568/4568 [==============================] - 0s 57us/step - loss: 3.1915 - acc: 0.1046\n",
      "Epoch 29/50\n",
      "4568/4568 [==============================] - 0s 50us/step - loss: 3.1872 - acc: 0.1049\n",
      "Epoch 30/50\n",
      "4568/4568 [==============================] - 0s 62us/step - loss: 3.1830 - acc: 0.1044\n",
      "Epoch 31/50\n",
      "4568/4568 [==============================] - 0s 50us/step - loss: 3.1813 - acc: 0.1057\n",
      "Epoch 32/50\n",
      "4568/4568 [==============================] - 0s 51us/step - loss: 3.1786 - acc: 0.1055\n",
      "Epoch 33/50\n",
      "4568/4568 [==============================] - 0s 53us/step - loss: 3.1771 - acc: 0.1062\n",
      "Epoch 34/50\n",
      "4568/4568 [==============================] - 0s 64us/step - loss: 3.1749 - acc: 0.1053\n",
      "Epoch 35/50\n",
      "4568/4568 [==============================] - 0s 56us/step - loss: 3.1735 - acc: 0.1053\n",
      "Epoch 36/50\n",
      "4568/4568 [==============================] - 0s 51us/step - loss: 3.1727 - acc: 0.1060\n",
      "Epoch 37/50\n",
      "4568/4568 [==============================] - 0s 50us/step - loss: 3.1702 - acc: 0.1064\n",
      "Epoch 38/50\n",
      "4568/4568 [==============================] - 0s 52us/step - loss: 3.1666 - acc: 0.1060\n",
      "Epoch 39/50\n",
      "4568/4568 [==============================] - 0s 51us/step - loss: 3.1639 - acc: 0.1075\n",
      "Epoch 40/50\n",
      "4568/4568 [==============================] - 0s 61us/step - loss: 3.1605 - acc: 0.1066\n",
      "Epoch 41/50\n",
      "4568/4568 [==============================] - 0s 61us/step - loss: 3.1599 - acc: 0.1086\n",
      "Epoch 42/50\n",
      "4568/4568 [==============================] - 0s 59us/step - loss: 3.1584 - acc: 0.1064\n",
      "Epoch 43/50\n",
      "4568/4568 [==============================] - 0s 53us/step - loss: 3.1583 - acc: 0.1073\n",
      "Epoch 44/50\n",
      "4568/4568 [==============================] - 0s 49us/step - loss: 3.1574 - acc: 0.1088\n",
      "Epoch 45/50\n",
      "4568/4568 [==============================] - 0s 52us/step - loss: 3.1537 - acc: 0.1060\n",
      "Epoch 46/50\n",
      "4568/4568 [==============================] - 0s 50us/step - loss: 3.1535 - acc: 0.1090\n",
      "Epoch 47/50\n",
      "4568/4568 [==============================] - 0s 54us/step - loss: 3.1529 - acc: 0.1090\n",
      "Epoch 48/50\n",
      "4568/4568 [==============================] - 0s 52us/step - loss: 3.1529 - acc: 0.1090\n",
      "Epoch 49/50\n",
      "4568/4568 [==============================] - 0s 50us/step - loss: 3.1508 - acc: 0.1088\n",
      "Epoch 50/50\n",
      "4568/4568 [==============================] - 0s 53us/step - loss: 3.1482 - acc: 0.1077\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "ll = model.fit(X, dummy_y, 32, 50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 59, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 59, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 59, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(np.array(X_test))\n",
    "class_labels = np.argmax(prediction, axis=1)\n",
    "labels = list(set(y))\n",
    "final_labels = [labels[i] for i in class_labels]\n",
    "print(final_labels)\n",
    "# for i in c\n",
    "# print(list(set(y)))\n",
    "# print(y[0])\n",
    "# print(dummy_y[0])\n",
    "# prediction = np.squeeze(prediction)\n",
    "# prediction = np.squeeze(scaler.inverse_transform(prediction.reshape(-1,1)))\n",
    "# prediction = [int(i) for i in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "69\n",
      "68\n",
      "63\n",
      "68\n",
      "61\n",
      "60\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "60\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "60\n",
      "60\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "69\n",
      "61\n",
      "63\n",
      "61\n",
      "68\n",
      "61\n",
      "69\n",
      "61\n",
      "68\n",
      "63\n",
      "60\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "60\n",
      "60\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "60\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "68\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "61\n",
      "60\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "61\n",
      "68\n",
      "60\n",
      "60\n",
      "61\n",
      "60\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "60\n",
      "61\n",
      "60\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "68\n",
      "61\n",
      "60\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "61\n",
      "68\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "61\n",
      "60\n",
      "60\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "61\n",
      "68\n",
      "60\n",
      "60\n",
      "61\n",
      "60\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "61\n",
      "68\n",
      "60\n",
      "60\n",
      "61\n",
      "68\n",
      "60\n",
      "60\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "60\n",
      "60\n",
      "61\n",
      "61\n",
      "68\n",
      "60\n",
      "60\n",
      "61\n",
      "68\n",
      "60\n",
      "68\n",
      "61\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "69\n",
      "68\n",
      "63\n",
      "68\n",
      "61\n",
      "60\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "60\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "60\n",
      "60\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "69\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "69\n",
      "61\n",
      "68\n",
      "63\n",
      "60\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "60\n",
      "60\n",
      "61\n",
      "60\n",
      "68\n",
      "61\n",
      "69\n",
      "61\n",
      "68\n",
      "60\n",
      "61\n",
      "61\n",
      "61\n",
      "60\n",
      "60\n",
      "61\n",
      "60\n",
      "61\n",
      "60\n",
      "61\n",
      "68\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "60\n",
      "61\n",
      "61\n",
      "61\n",
      "68\n",
      "60\n",
      "61\n",
      "68\n",
      "61\n",
      "60\n",
      "60\n",
      "60\n",
      "61\n",
      "68\n",
      "60\n",
      "61\n",
      "61\n",
      "60\n",
      "61\n",
      "60\n",
      "61\n",
      "60\n",
      "60\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "mid = MidiFile()\n",
    "track = MidiTrack()\n",
    "t = 0\n",
    "for note in final_labels:\n",
    "    # 147 means note_on\n",
    "    # 67 is velosity\n",
    "    print(note)\n",
    "    note = np.asarray([147, note, 67])\n",
    "    bytes = note.astype(int)\n",
    "    msg = Message.from_bytes(bytes[0:3])\n",
    "    t += 1\n",
    "    msg.time = t\n",
    "    track.append(msg)\n",
    "mid.tracks.append(track)\n",
    "mid.save('20_epoch_8_note_seq_CE.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
